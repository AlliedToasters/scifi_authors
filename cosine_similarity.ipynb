{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.markers import MarkerStyle\n",
    "from matplotlib.colors import Colormap\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "from cycler import cycler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import spatial\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('docs.csv').sample(frac=1, random_state=0) #load dataset and shuffle rows\n",
    "df.index = range(0, 100) #reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reserve holdout group\n",
    "train = df.loc[:74].copy() #train group\n",
    "test = df.loc[75:].copy() #holdout group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lemmas(document):\n",
    "    \"\"\"takes raw spacy parse and returns only\n",
    "    word lemmas, in or out of vocab.\n",
    "    \"\"\"\n",
    "    result = ''\n",
    "    for token in document:\n",
    "        if not token.is_space and not token.is_punct and not (token.lemma_ == '-PRON-'):\n",
    "            result += token.lemma_ + ' '\n",
    "        elif token.lemma_ == '-PRON-':\n",
    "            result += token.orth_ + ' '\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prs = spacy.load('en')\n",
    "train['raw_parse'] = train.text.apply(prs)\n",
    "train['lemmas'] = train.raw_parse.apply(get_lemmas)\n",
    "vec = TfidfVectorizer(stop_words='english', min_df=2, max_df=.99, ngram_range=(1, 3))\n",
    "svd = TruncatedSVD(n_components=74, random_state=0, algorithm='arpack')\n",
    "norm = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, norm)\n",
    "raw_vec_train = vec.fit_transform(train.lemmas)\n",
    "train_mat = lsa.fit_transform(raw_vec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode the authors and the source texts for cluster evaluation\n",
    "author_encoding = {}\n",
    "code = iter(range(0, len(df.author.unique())))\n",
    "for auth in df.author.unique():\n",
    "    author_encoding[auth] = next(code)\n",
    "    \n",
    "train['author_code'] = train.author.apply(lambda x: author_encoding[x])\n",
    "test['author_code'] = test.author.apply(lambda x: author_encoding[x])\n",
    "\n",
    "title_encoding = {}\n",
    "code = iter(range(0, len(df.title.unique())))\n",
    "for tit in df.title.unique():\n",
    "    title_encoding[tit] = next(code)\n",
    "    \n",
    "train['title_code'] = train.title.apply(lambda x: title_encoding[x])\n",
    "test['title_code'] = test.title.apply(lambda x: title_encoding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = vec.fit_transform(train.lemmas)\n",
    "train_mat = lsa.fit_transform(trans)\n",
    "ap = AffinityPropagation()\n",
    "np.unique(ap.fit_predict(train_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ap_cluster'] = ap.predict(train_mat) #record cluster assignments for training group\n",
    "clusters = {}\n",
    "for clust in train.ap_cluster.unique():\n",
    "    clusters[clust] = (\n",
    "        list(train[train.ap_cluster==clust].author.unique()), \n",
    "        list(train[train.ap_cluster==clust].title.unique()),\n",
    "    )\n",
    "\n",
    "authors = {}\n",
    "for auth in train.author.unique():\n",
    "    authors[auth] = train[train.author==auth].ap_cluster.unique()\n",
    "    \n",
    "#for clust in range(0, len(clusters)):\n",
    "#    print('cluster ', clust, 'authors: ', clusters[clust][0], 'source texts: ', clusters[clust][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_frame = pd.DataFrame(index=[clust for clust in clusters], columns=['number', 'author', 'titles', 'center'])\n",
    "cluster_frame['number'] = cluster_frame.index\n",
    "for clust in clusters:\n",
    "    cluster_frame.at[clust, 'author'] = clusters[clust][0][0]\n",
    "    cluster_frame.at[clust, 'titles'] = clusters[clust][1]\n",
    "    cluster_frame.at[clust, 'center'] = ap.cluster_centers_[clust]\n",
    "cf = cluster_frame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>author</th>\n",
       "      <th>titles</th>\n",
       "      <th>center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dick</td>\n",
       "      <td>[variableman]</td>\n",
       "      <td>[0.284126030993, -0.125934183839, -0.039002128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>reynolds</td>\n",
       "      <td>[spaceman_spree]</td>\n",
       "      <td>[0.272280459418, -0.0409121095981, -0.02227118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>reynolds</td>\n",
       "      <td>[off_course]</td>\n",
       "      <td>[0.292357811895, -0.0209455648265, -0.00598433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>asimov</td>\n",
       "      <td>[nuclear_energy_3]</td>\n",
       "      <td>[0.142144408993, -0.342149389719, -0.203688871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dick</td>\n",
       "      <td>[mrspaceship]</td>\n",
       "      <td>[0.304801510613, 0.04299048711, 0.001864242480...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>herbert</td>\n",
       "      <td>[haystack]</td>\n",
       "      <td>[0.351572381815, 0.648848397327, -0.2115489725...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>asimov</td>\n",
       "      <td>[youth]</td>\n",
       "      <td>[0.307579761401, 0.0531959177178, -0.030131251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>rockwell</td>\n",
       "      <td>[space_pirates, venus_revolt]</td>\n",
       "      <td>[0.352480631284, -0.00555398358782, 0.68154701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>verne</td>\n",
       "      <td>[20000leagues]</td>\n",
       "      <td>[0.239652523079, -0.152336798533, -0.042455368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>pohl</td>\n",
       "      <td>[skysearch]</td>\n",
       "      <td>[0.288039319237, 0.0217771658353, -0.070395180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>bradbury</td>\n",
       "      <td>[futuria]</td>\n",
       "      <td>[0.311245109232, -0.0248207390329, 0.013337984...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>bradbury</td>\n",
       "      <td>[futuria]</td>\n",
       "      <td>[0.317452643207, -0.0479860291575, -0.05108798...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>herbert</td>\n",
       "      <td>[old_rambling_house]</td>\n",
       "      <td>[0.254864647026, 0.0443182077988, -0.051363987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>wells</td>\n",
       "      <td>[discovery_future]</td>\n",
       "      <td>[0.291184701334, -0.212347577873, -0.165675558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>bradbury</td>\n",
       "      <td>[a_little_journey]</td>\n",
       "      <td>[0.252483292679, 0.0288731820863, 0.0126193187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>verne</td>\n",
       "      <td>[moon_journey]</td>\n",
       "      <td>[0.235872814387, -0.0978573751346, -0.00917487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>vonnegut</td>\n",
       "      <td>[trip_up_yonder, 2BR02B]</td>\n",
       "      <td>[0.207363814138, 0.0511069153351, -0.008460573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>pohl</td>\n",
       "      <td>[tunnel]</td>\n",
       "      <td>[0.288539978571, 0.0574049252035, -0.022223887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>wells</td>\n",
       "      <td>[moon_men]</td>\n",
       "      <td>[0.399268996237, -0.0662997851542, -0.09357616...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number    author                         titles  \\\n",
       "0        0      dick                  [variableman]   \n",
       "1        1  reynolds               [spaceman_spree]   \n",
       "2        2  reynolds                   [off_course]   \n",
       "3        3    asimov             [nuclear_energy_3]   \n",
       "4        4      dick                  [mrspaceship]   \n",
       "5        5   herbert                     [haystack]   \n",
       "6        6    asimov                        [youth]   \n",
       "7        7  rockwell  [space_pirates, venus_revolt]   \n",
       "8        8     verne                 [20000leagues]   \n",
       "9        9      pohl                    [skysearch]   \n",
       "10      10  bradbury                      [futuria]   \n",
       "11      11  bradbury                      [futuria]   \n",
       "12      12   herbert           [old_rambling_house]   \n",
       "13      13     wells             [discovery_future]   \n",
       "14      14  bradbury             [a_little_journey]   \n",
       "15      15     verne                 [moon_journey]   \n",
       "16      16  vonnegut       [trip_up_yonder, 2BR02B]   \n",
       "17      17      pohl                       [tunnel]   \n",
       "18      18     wells                     [moon_men]   \n",
       "\n",
       "                                               center  \n",
       "0   [0.284126030993, -0.125934183839, -0.039002128...  \n",
       "1   [0.272280459418, -0.0409121095981, -0.02227118...  \n",
       "2   [0.292357811895, -0.0209455648265, -0.00598433...  \n",
       "3   [0.142144408993, -0.342149389719, -0.203688871...  \n",
       "4   [0.304801510613, 0.04299048711, 0.001864242480...  \n",
       "5   [0.351572381815, 0.648848397327, -0.2115489725...  \n",
       "6   [0.307579761401, 0.0531959177178, -0.030131251...  \n",
       "7   [0.352480631284, -0.00555398358782, 0.68154701...  \n",
       "8   [0.239652523079, -0.152336798533, -0.042455368...  \n",
       "9   [0.288039319237, 0.0217771658353, -0.070395180...  \n",
       "10  [0.311245109232, -0.0248207390329, 0.013337984...  \n",
       "11  [0.317452643207, -0.0479860291575, -0.05108798...  \n",
       "12  [0.254864647026, 0.0443182077988, -0.051363987...  \n",
       "13  [0.291184701334, -0.212347577873, -0.165675558...  \n",
       "14  [0.252483292679, 0.0288731820863, 0.0126193187...  \n",
       "15  [0.235872814387, -0.0978573751346, -0.00917487...  \n",
       "16  [0.207363814138, 0.0511069153351, -0.008460573...  \n",
       "17  [0.288539978571, 0.0574049252035, -0.022223887...  \n",
       "18  [0.399268996237, -0.0662997851542, -0.09357616...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = cf.sort_values('number')\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Similarity\n",
    "We can use cosine similarity to find similarity between cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix(cf):\n",
    "    \"\"\"Computes a similarity matrix between all cluster centers.\n",
    "    The returned matrix axes are ordered by the numeric values\n",
    "    of the clusters.\n",
    "    \"\"\"\n",
    "    result = np.matrix(np.zeros((len(cf), len(cf))))\n",
    "    for i in range(0, len(cf)):\n",
    "        for j in range(0, len(cf)):\n",
    "            similarity = 1 - spatial.distance.cosine(cf.loc[i].center, cf.loc[j].center)\n",
    "            result[i, j] = similarity\n",
    "    return result\n",
    "\n",
    "def get_most_similar(cluster, sim, get_similarity=False):\n",
    "    \"\"\"Takes a cluster number and the cluster frame and\n",
    "    computes the most similar cluster in terms of maximum\n",
    "    cosine between cluster centers.\n",
    "    \"\"\"\n",
    "    row = np.array(sim[cluster, :])\n",
    "    result = np.argsort(row)[0][1]\n",
    "    if get_similarity:\n",
    "        return result, row[:, result][0]\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def get_similarity(c1, c2, sim):\n",
    "    \"\"\"Takes a cluster number and the cluster frame and\n",
    "    computes the most similar cluster in terms of maximum\n",
    "    cosine between cluster centers.\n",
    "    \"\"\"\n",
    "    return sim[c1, c2]\n",
    "\n",
    "sim = get_similarity_matrix(cf) #compute similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I look at similarity in this way, we can get some interesting snippets of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cluster similarity to most similar cluster:  0.0313463122032\n",
      "\n",
      "\n",
      "Cluster with least similarity to any others: \n",
      "\n",
      "author                asimov\n",
      "titles    [nuclear_energy_3]\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "most_similar = []\n",
    "for clust in cf.index:\n",
    "    most_similar.append(get_most_similar(clust, sim, get_similarity=True)[1])\n",
    "mean_sim = np.mean(most_similar)\n",
    "print('Mean cluster similarity to most similar cluster: ', mean_sim)\n",
    "print('\\n')\n",
    "print('Cluster with least similarity to any others: \\n')\n",
    "print(cf.loc[np.argmin(most_similar)][['author', 'titles']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean similarity to othe nearest cluster, of course, has little meaning with no other values to compare it to. It does, however, give us a benchmark for other similarity values.<br>\n",
    "I can use this similarity to investigate some of the problems I had. The biggest problem was a misassignment: An excerpt from Vonnegut was assigned to a cluster belonging to Wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_authors(author, cf, sim):\n",
    "    \"\"\"Takes an author name, the cluster dataframe, and similarity matrix\n",
    "    and returns a list of the most similar authors (can be one or many\n",
    "    because of multiple clusters per author.)\n",
    "    \"\"\"\n",
    "    author_clusters = cf[cf.author==author].number.unique()\n",
    "    similar_clusters = []\n",
    "    for clust in author_clusters:\n",
    "        similar_clusters.append(get_most_similar(clust, sim))\n",
    "    similar_clusters = list(set(similar_clusters))\n",
    "    similar_authors = []\n",
    "    for clust in similar_clusters:\n",
    "        similar_authors.append(cf.loc[clust].author)\n",
    "    return set(similar_authors)\n",
    "\n",
    "def get_similar_document(title, cf, sim):\n",
    "    \"\"\"Takes a document title, the cluster dataframe, and similarity matrix\n",
    "    and returns a list of the most similar documents (can be one or many\n",
    "    because of multiple clusters per title.)\n",
    "    \"\"\"\n",
    "    title_clusters = []\n",
    "    for i in cf.index:\n",
    "        if title in cf.loc[i].titles:\n",
    "            title_clusters.append(i)\n",
    "    similar_clusters = []\n",
    "    for clust in title_clusters:\n",
    "        similar_clusters.append(get_most_similar(clust, sim))\n",
    "    similar_clusters = list(set(similar_clusters))\n",
    "    similar_titles = []\n",
    "    for clust in similar_clusters:\n",
    "        similar_titles += [x for x in cf.loc[clust].titles]\n",
    "    return set(similar_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar authors to Wells: \n",
      "{'vonnegut', 'herbert'}\n",
      "Similarity between Vonnegut cluster and Disovery of the Future by Wells cluster:  0.0552353680766\n",
      "Similarity scaled by mean maximum similarity between clusters:  1.7621009999\n"
     ]
    }
   ],
   "source": [
    "print('Similar authors to Wells: ')\n",
    "print(get_similar_authors('wells', cf, sim))\n",
    "print('Similarity between Vonnegut cluster and Disovery of the Future by Wells cluster: ', get_similarity(13, 16, sim))\n",
    "print('Similarity scaled by mean maximum similarity between clusters: ', get_similarity(13, 16, sim)/mean_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a high similarity between Wells' Discovery of the Future cluster and Vonnegut's only cluster, which gives us some insight into why the misassignment occured.<br><br>\n",
    "With these tools, we can \"most similar\" authors and \"most similar\" titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar authors to dick: \n",
      "{'vonnegut', 'pohl'}\n",
      "Most similar authors to vonnegut: \n",
      "{'verne'}\n",
      "Most similar authors to asimov: \n",
      "{'dick', 'reynolds'}\n",
      "Most similar authors to reynolds: \n",
      "{'vonnegut', 'verne'}\n",
      "Most similar authors to verne: \n",
      "{'herbert', 'asimov'}\n",
      "Most similar authors to wells: \n",
      "{'vonnegut', 'herbert'}\n",
      "Most similar authors to bradbury: \n",
      "{'vonnegut', 'verne', 'herbert'}\n",
      "Most similar authors to herbert: \n",
      "{'verne'}\n",
      "Most similar authors to pohl: \n",
      "{'verne'}\n",
      "Most similar authors to rockwell: \n",
      "{'pohl'}\n",
      "\n",
      "\n",
      "Most similar titles to variableman: \n",
      "{'skysearch'}\n",
      "Most similar titles to trip_up_yonder: \n",
      "{'20000leagues'}\n",
      "Most similar titles to youth: \n",
      "{'variableman'}\n",
      "Most similar titles to spaceman_spree: \n",
      "{'moon_journey'}\n",
      "Most similar titles to 20000leagues: \n",
      "{'old_rambling_house'}\n",
      "Most similar titles to discovery_future: \n",
      "{'haystack'}\n",
      "Most similar titles to futuria: \n",
      "{'trip_up_yonder', '2BR02B', 'moon_journey'}\n",
      "Most similar titles to off_course: \n",
      "{'trip_up_yonder', '2BR02B'}\n",
      "Most similar titles to moon_men: \n",
      "{'trip_up_yonder', '2BR02B'}\n",
      "Most similar titles to moon_journey: \n",
      "{'nuclear_energy_3'}\n",
      "Most similar titles to a_little_journey: \n",
      "{'old_rambling_house'}\n",
      "Most similar titles to nuclear_energy_3: \n",
      "{'spaceman_spree'}\n",
      "Most similar titles to mrspaceship: \n",
      "{'trip_up_yonder', '2BR02B'}\n",
      "Most similar titles to haystack: \n",
      "{'20000leagues'}\n",
      "Most similar titles to skysearch: \n",
      "{'20000leagues'}\n",
      "Most similar titles to space_pirates: \n",
      "{'skysearch'}\n",
      "Most similar titles to venus_revolt: \n",
      "{'skysearch'}\n",
      "Most similar titles to tunnel: \n",
      "{'20000leagues'}\n",
      "Most similar titles to old_rambling_house: \n",
      "{'20000leagues'}\n",
      "Most similar titles to 2BR02B: \n",
      "{'20000leagues'}\n"
     ]
    }
   ],
   "source": [
    "for auth in authors:\n",
    "    print('Most similar authors to {}: '.format(auth))\n",
    "    print(get_similar_authors(auth, cf, sim))\n",
    "    \n",
    "print('\\n')\n",
    "for title in df.title.unique():\n",
    "    print('Most similar titles to {}: '.format(title))\n",
    "    print(get_similar_document(title, cf, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these results, we can see that many of the \"most similar\" cluster pairs do not belong to the same author. This is a bad sign for our cluster analysis' ability to pick up on differences between authors; it seems to do a much better job of identifying source texts than authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Environment (conda_dspy3)",
   "language": "python",
   "name": "conda_dspy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
